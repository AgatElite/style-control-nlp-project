\documentclass[sn-basic, Numbered]{sn-jnl}

\usepackage{graphicx}
\usepackage{multirow}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage[title]{appendix}
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{manyfoot}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{listings}

% Set the title and author info
\title[Style+Control]{Style+Control: Disentangling Literary Style from Semantic Content in Vector Space}

% Author details
\author{\fnm{Alex} \sur{Tulip}}

\affil{\orgdiv{Department of Computer Science}, \orgname{Università degli Studi di Milano}, \orgaddress{\city{Milan}, \country{Italy}}}

\abstract{
This study investigates how literary style is encoded in the vector space of Large Language Models (LLMs). I specifically look at whether I can separate the distinct writing styles of Jane Austen and Herman Melville. Using a dataset of non-parallel texts and the BGE embedding model, I show that authors form distinct clusters in high-dimensional space (99\% classification accuracy). However, I find that "style" is not a single point but a broad cloud. I also performed a style transfer experiment using Gemini-2.5-Flash. My results show a conflict between content and style: the final semantic layers of the model focus on the original content and fail to detect the style change. In contrast, the lower layers (Layer 2) successfully identify the new style. This suggests that literary style is encoded in the early structural layers of the model, separate from the high-level meaning found in later layers.
}

\begin{document}

\maketitle

\section{Introduction}\label{sec1}

Natural Language Processing (NLP) has become very good at understanding meaning. Modern models like BERT or RoBERTa are trained to see sentences like "The dog ate" and "The canine fed" as almost identical because they mean the same thing. However, in literature, the \textit{difference} between those two sentences—the style—is just as important as the meaning. As noted in recent surveys on Neural Style Transfer (NST) \cite{jing2019neural}, defining "style" is much harder and more subjective than defining content.

In this project, I address a specific question: \textbf{Is literary style stored in a separate region of the vector space in modern LLMs, and can I move text from one style to another without losing the original meaning?}

To test this, I chose two authors with very different voices: Jane Austen (known for polite society and domestic realism) and Herman Melville (known for nautical terms and complex, archaic language). I used text from \textit{Emma} and \textit{Moby Dick} to see if their styles could be separated and if an LLM could rewrite Austen's text in Melville's voice.

\section{Methodology}\label{sec2}

My methodology follows three main steps: data preparation, embedding analysis, and style transfer generation.

\subsection{Dataset Curation}
Since there is no existing dataset where Melville rewrote Austen, I created a non-parallel dataset using the Project Gutenberg versions of \textit{Emma} and \textit{Moby Dick}. I split the raw text into 600 chunks (300 per author), each about 128 tokens long. This length ensures the model has enough context to detect the style.

\subsection{Models}
\begin{itemize}
    \item \textbf{Embedding:} I used \texttt{BAAI/bge-small-en-v1.5}. While Pan et al. \cite{pan2024unsupervised} used RoBERTa, I chose BGE because it is optimized for semantic retrieval. Using a model designed to focus on \textit{meaning} is a strong test: can style differences survive in a vector space designed to ignore them?
    \item \textbf{Generation:} For the style transfer task, I used \texttt{Google Gemini-2.5-Flash}. I chose this model for its speed and ability to follow complex instructions.
\end{itemize}

\subsection{Evaluation Metrics}
Following the standards for unsupervised style transfer \cite{pan2024unsupervised}, I used three metrics:
\begin{enumerate}
    \item \textbf{Geometric Distance:} I calculated the distance between the text vectors and the center of each author's cluster to measure the shift in style.
    \item \textbf{Style Probability (ACC):} I trained a Logistic Regression classifier to predict the author based on the embeddings.
    \item \textbf{Fluency (PPL):} I calculated Perplexity using GPT-2 to ensure the generated text was still valid English.
\end{enumerate}

\subsection{Layer-Wise Analysis}
Inspired by findings in image processing where style (texture) is found in lower layers and content is found in higher layers \cite{cai2023image}, I analyzed the internal states of the Transformer. I extracted embeddings from both \textbf{Layer 2} (early layer, focuses on syntax) and the \textbf{Final Layer} (late layer, focuses on meaning) to see where the style information is stored.

\section{Experimental Results}\label{sec3}

\subsection{Vector Space Topology}
First, I projected the 600 text chunks into the embedding space. As shown in Fig.~\ref{fig1}, the t-SNE visualization shows two completely separate islands for the two authors.

\begin{figure}[h]
\centering
\includegraphics[width=0.9\textwidth]{figure1_clusters.png}
\caption{t-SNE visualization showing clear separation between Austen (Cluster 0) and Melville (Cluster 1).}
\label{fig1}
\end{figure}

To measure this, I used K-Means clustering ($k=2$). The algorithm achieved near-perfect separation, matching the real labels with \textbf{99.1\% accuracy} (Table \ref{tab1}).

\begin{table}[h]
\begin{center}
\begin{minipage}{174pt}
\caption{Confusion Matrix of Unsupervised Clustering}\label{tab1}%
\begin{tabular}{@{}lll@{}}
\toprule
Label & Cluster 0 (Austen) & Cluster 1 (Melville) \\
\midrule
Austen & 300 & 0 \\
Melville & 6 & 294 \\
\botrule
\end{tabular}
\end{minipage}
\end{center}
\end{table}

However, I found the \textbf{Silhouette Score} was low at \textbf{0.119}. This does not mean the clustering is bad. In this context, it means that while the authors are separate, their clusters are not tight points. They are broad clouds. This makes sense because the books cover many different topics; Austen talking about a wedding is mathematically far from Austen talking about a picnic, even if the style is the same.

\subsection{Style Transfer Experiment}
I selected a text from Austen describing a carriage ride with Mr. Elton. I then asked Gemini-2.5-Flash to rewrite it in the style of Melville, providing a real Melville paragraph as an example.

\textbf{Qualitative Result:}
The generation was successful.
\begin{quote}
\textit{Original (Austen):} "her heroism reached only to silence." \\
\textit{Rewritten (Melville):} "Her valor, a fragile, land-locked thing, sought its only refuge in the mute."
\end{quote}
The model successfully added archaic words ("valor," "mute") and nautical metaphors ("land-locked"), changing the tone significantly.

\textbf{Quantitative Analysis:}
\begin{itemize}
    \item \textbf{Fluency:} The Perplexity (PPL) increased from \textbf{68.24} (Original) to \textbf{101.67} (Rewritten). This increase does not mean the text is bad. Instead, it quantifies the higher complexity of Melville's style compared to Austen's simpler prose.
    \item \textbf{Vector Shift:} In the semantic embedding space (Final Layer), the vector moved from the Austen center (Distance: 0.099) to the Melville center (Distance: 0.271). However, it remained closer to Austen (0.259), meaning it failed to fully cross the boundary.
    \item \textbf{Classification:} The style classifier probability shifted from 91.4\% Austen to 54.9\% Melville. While this is technically a "success" (crossing 50\%), the margin is very slim.
\end{itemize}

\subsection{Layer-Wise Disentanglement}
To understand why the semantic vector struggled to classify the text as Melville, I analyzed the embeddings at \textbf{Layer 2}.

\begin{table}[h]
\caption{Comparison of Distances to Centroids by Layer}\label{tab2}
\begin{tabular}{@{}llll@{}}
\toprule
Layer & Dist. to Austen & Dist. to Melville & Result \\
\midrule
Semantic (Final) & \textbf{0.2596} & 0.2716 & Fail (Closer to Source)\\
Syntactic (Layer 2) & 0.1325 & \textbf{0.0934} & Success (Closer to Target)\\
\botrule
\end{tabular}
\end{table}

As shown in Table \ref{tab2}, I found that the early layer successfully identified the text as Melville. Visualizing the attention weights (Fig.~\ref{fig2} and Fig.~\ref{fig3}) explains why. Layer 2 shows a strong "diagonal" pattern, meaning words pay attention to their immediate neighbors (local syntax). Layer 12, on the other hand, spreads attention globally to find named entities.

\begin{figure}[h]
\centering
\begin{minipage}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figure2_attention_layer2.png}
    \caption{Layer 2 Attention Map showing diagonal focus (local syntax).}
    \label{fig2}
\end{minipage}\hfill
\begin{minipage}{0.48\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figure3_attention_layer12.png}
    \caption{Layer 12 Attention Map showing diffused focus (global semantics)}
    \label{fig3}
\end{minipage}
\end{figure}

\section{Concluding Remarks}\label{sec4}

This study confirms that literary style is a measurable phenomenon in vector space, but it is deeply mixed with content.

My results highlight a key limitation in current embeddings: the "Content Anchor." Because the rewritten text kept Austen's characters ("Mr. Elton," "Mrs. Goddard"), the final layer of the model—which looks for entities—refused to classify the text as Melville, despite the obvious style change.

However, by looking at the lower layers of the model (Layer 2), I showed that the style shift \textit{was} successfully encoded. The syntax-focused attention in the early layers correctly identified the Melvillean structure. This aligns with the findings of Cai et al. \cite{cai2023image} regarding the hierarchical nature of feature extraction. Future work in text style transfer should use these lower-layer embeddings to better separate "how" something is written from "what" is written.

\section*{AI Usage Disclaimer}
Parts of this project code and the conceptual outlining were developed with the assistance of \textbf{Google Gemini}. The AI was used to support the drafting of boilerplate code (matplotlib/sklearn), debugging dimension mismatch errors, and refining the choices in the project. All outputs have been modified, verified, and integrated into the final workflow by me.

\bibliography{sn-bibliography}

\begin{thebibliography}{9}

\bibitem{jing2019neural}
Jing, Y., Yang, Y., Feng, Z., Ye, J., Yu, Y., \& Song, M. (2019). Neural style transfer: A review. \textit{IEEE transactions on visualization and computer graphics}, 26(11), 3365-3385.

\bibitem{cai2023image}
Cai, Q., Ma, M., Wang, C., \& Li, H. (2023). Image neural style transfer: A review. \textit{Computers and Electrical Engineering}, 108, 108723.

\bibitem{pan2024unsupervised}
Pan, L., Lan, Y., Li, Y., \& Qian, W. (2024). Unsupervised Text Style Transfer via LLMs and Attention Masking with Multi-way Interactions. \textit{arXiv preprint arXiv:2402.13647}.

\end{thebibliography}

\end{document}